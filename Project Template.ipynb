{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import psycopg2\n",
    "\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"alMZBjkqoiGjUdoR8UIDOouaq\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"resource/erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"resource/5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"postgres\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b18f12-c0ce-4b9c-adc1-805703edc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url, force=False, query=None):\n",
    "    \"\"\"\n",
    "    Download NYC GeoJSON data and save it to a local file.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The URL from which to download the data.\n",
    "        force (bool, optional): If True, force downloading even if the file exists locally. Defaults to False.\n",
    "        query (str, optional): A query string to filter the data during download. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        pathlib.Path: The local path to the downloaded GeoJSON file.\n",
    "    \"\"\"\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        \n",
    "        headers = {'X-App-Token': NYC_DATA_APP_TOKEN}\n",
    "        params = {\n",
    "        \"$limit\": 10000,\n",
    "        \"$offset\": 0,\n",
    "        \"$select\": \"*\",\n",
    "        \"$where\": query\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(response.json(), f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dadfec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ee8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \"\"\"\n",
    "    Load and clean zipcode data from a specified file.\n",
    "\n",
    "    This function reads geographic data of zipcodes from a given file,\n",
    "    converts the coordinate reference system to EPSG 4326, and selects specific columns.\n",
    "    It selects relevant columns, renames them, and removes rows with missing values.\n",
    "\n",
    "    Args:\n",
    "        zipcode_datafile (str): The file path of the zipcode data file.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: A cleaned GeoDataFrame with selected information about zipcodes.\n",
    "    \"\"\"\n",
    "    zipcode_data = gpd.read_file(zipcode_datafile)\n",
    "    zipcode_data = zipcode_data.to_crs(epsg=4326)\n",
    "    zipcode_data = zipcode_data[['ZIPCODE', 'COUNTY', 'geometry']]\n",
    "    zipcode_data = zipcode_data.rename(columns={'ZIPCODE': 'zipcode', 'COUNTY': 'county'})\n",
    "    zipcode_data = zipcode_data.dropna()\n",
    "    \n",
    "    return zipcode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    \"\"\"\n",
    "    Download and clean New York City's 311 service request data for a specific date range.\n",
    "    \n",
    "    The function filters data for requests made on from January 1, 2015 to September 30, 2023.\n",
    "    It selects relevant columns, renames them, and removes rows with missing values.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: Cleaned data with selected information about 311 service requests.\n",
    "    \"\"\"\n",
    "    query_311 = \"created_date between '2023-09-30T12:00:00' and '2023-09-30T23:59:59'\"\n",
    "    nyc_311_data = download_nyc_geojson_data(f\"{BASE_NYC_DATA_URL}{NYC_DATA_311}\", force=True, query=query_311)\n",
    "    nyc_311_data = gpd.read_file(nyc_311_data)\n",
    "    nyc_311_data = nyc_311_data.to_crs(epsg=4326)\n",
    "    nyc_311_data = nyc_311_data[['unique_key', 'incident_zip', 'created_date', 'complaint_type', 'geometry']]\n",
    "    nyc_311_data = nyc_311_data.rename(columns={'unique_key': 'id', 'incident_zip': 'zipcode', 'created_date': 'date'})\n",
    "    nyc_311_data = nyc_311_data.dropna()\n",
    "\n",
    "    return nyc_311_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dcc9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    \"\"\"\n",
    "    Download and clean New York City tree data.\n",
    "    \n",
    "    This function downloads NYC tree data in GeoJSON format from a NYC Open Data,\n",
    "    reads it into a GeoDataFrame, converts its coordinate reference system to EPSG 4326,\n",
    "    selects specific columns, renames some for clarity, and removes rows with missing values.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: A GeoDataFrame containing the cleaned NYC tree data.\n",
    "                          The data includes columns like tree ID, zipcode, species,\n",
    "                          health, status, and geometry after renaming and dropping\n",
    "                          missing values.\n",
    "    \"\"\"\n",
    "    nyc_trees_data = download_nyc_geojson_data(f\"{BASE_NYC_DATA_URL}{NYC_DATA_TREES}\", force=True)\n",
    "    nyc_trees_data = gpd.read_file(nyc_trees_data)\n",
    "    nyc_trees_data = nyc_trees_data.to_crs(epsg=4326)\n",
    "    nyc_trees_data = nyc_trees_data[[\"tree_id\", \"zipcode\", \"spc_common\", \"health\", \"status\", \"geometry\"]]\n",
    "    nyc_trees_data = nyc_trees_data.rename(columns={\"tree_id\": \"id\", \"spc_common\": \"species\"})\n",
    "    nyc_trees_data = nyc_trees_data.dropna()\n",
    "    \n",
    "    return nyc_trees_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ff49f-a18b-4fc0-8da6-6834a10d11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data(): \n",
    "    \"\"\"\n",
    "    Load and clean Zillow rental data for New York City.\n",
    "    \n",
    "    This function reads Zillow rental data from a CSV file, filters it for entries\n",
    "    pertaining to New York City, and selects specific columns relevant to rental\n",
    "    prices. The columns are then renamed for clarity, and rows with missing values\n",
    "    are removed to ensure the quality of data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing cleaned Zillow rental data with columns for \n",
    "                   Zillow region ID, zipcode, and rental prices for August and September 2023.\n",
    "    \"\"\"\n",
    "    zillow_data = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "    zillow_data = zillow_data[zillow_data[\"City\"]==\"New York\"]\n",
    "\n",
    "    cols_to_keep = ['RegionID', 'RegionName']\n",
    "    cols_to_melt = [col for col in zillow_data.columns if col.startswith('20')]\n",
    "    zillow_data = zillow_data[cols_to_keep + cols_to_melt]\n",
    "    zillow_data_long = pd.melt(zillow_data, id_vars=cols_to_keep, value_vars=cols_to_melt,\n",
    "                                var_name='date', value_name='rent')\n",
    "    zillow_data_long['date'] = pd.to_datetime(zillow_data_long['date'], format='%Y/%m/%d')\n",
    "    zillow_data_long['RegionName'] = zillow_data_long['RegionName'].astype(str)\n",
    "    zillow_data_long = zillow_data_long.rename(columns={\"RegionID\": \"region_id\", \"RegionName\": \"zipcode\"})\n",
    "\n",
    "    zillow_data_long\n",
    "    \n",
    "    return zillow_data_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"\n",
    "    Load and combine multiple datasets into a single collection.\n",
    "\n",
    "    This function aggregates four different datasets: zipcode data, 311 service request data,\n",
    "    tree census data, and Zillow rental data, each of which is loaded and cleaned by their\n",
    "    respective functions. The datasets are primarily focused on New York City information.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing four cleaned datasets (GeoDataFrames and DataFrame).\n",
    "               These are: zipcode data, 311 service request data, tree census data,\n",
    "               and Zillow rental data.\n",
    "    \"\"\"\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    \n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349fbdd-67d0-40a4-97a0-d9b8c8ec8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_new_postgis_database(username, db_name, password):\n",
    "    \"\"\"\n",
    "    Setup a new PostGIS database in PostgreSQL.\n",
    "\n",
    "    Args:\n",
    "        username (str): Username for the PostgreSQL database.\n",
    "        db_name (str): Name of the database to setup.\n",
    "        password (str): Password for the specified user.\n",
    "\n",
    "    Returns:\n",
    "        conn: A connection object to the created database.\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(\n",
    "        dbname = db_name, \n",
    "        user = username,\n",
    "        password = password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ed80d-7b60-484f-a123-23b673b0f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_new_postgis_database(DB_USER, DB_NAME, DB_PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d72390-3c2d-4856-82c0-3284e8ccb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac07405-dc2b-47af-9dad-6a9b94d2b34c",
   "metadata": {},
   "source": [
    "#### Option 1: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d0cc6-74b3-4d35-a454-57f647c9f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the SQL statements to create your 4 tables\n",
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS zipcodes\n",
    "(\n",
    "    zipcode TEXT PRIMARY KEY,\n",
    "    county TEXT,\n",
    "    geometry GEOMETRY(Polygon, 4326)\n",
    ");\n",
    "CREATE INDEX zipcodes_geom_idx ON zipcodes USING GIST (geometry);\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS complaints\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    zipcode TEXT,\n",
    "    date TIMESTAMP,\n",
    "    complaint_type TEXT,\n",
    "    geometry GEOMETRY(Point, 4326)\n",
    ");\n",
    "CREATE INDEX complaints_geom_idx ON complaints USING GIST (geometry);\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS trees\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    zipcode TEXT,\n",
    "    species TEXT,\n",
    "    health TEXT,\n",
    "    status TEXT,\n",
    "    geometry GEOMETRY(Point, 4326)\n",
    ");\n",
    "CREATE INDEX trees_geom_idx ON trees USING GIST (geometry);\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS rents\n",
    "(\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    region_id INTEGER,\n",
    "    zipcode TEXT,\n",
    "    date DATE,\n",
    "    rent FLOAT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d86f6-ff6e-4bb8-8fa2-df0d4282e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(\"DROP TABLE IF EXISTS zipcodes, complaints, trees, rents;\")\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eacd37-4fd7-4768-b689-88b07d5c234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using SQL (as opposed to SQLAlchemy), execute the schema files to create tables\n",
    "with engine.connect() as connection:\n",
    "    with open(DB_SCHEMA_FILE, 'r') as schema_file:\n",
    "        schema_sql = schema_file.read()\n",
    "        connection.execute(db.text(schema_sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a2d89-b276-4d44-a0ef-3631eb686e84",
   "metadata": {},
   "source": [
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c42e1-4ad4-4c43-a2ba-1dbcac1de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class Tree(Base):\n",
    "    __tablename__ = \"trees\"\n",
    "\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a9c3d-e6d6-4e01-8247-e9d465381ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66af67-afb8-4f0d-bb57-552972f8e4b8",
   "metadata": {},
   "source": [
    "#### Option 1: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e37800-cd95-44b5-9c21-eb7ac2b2e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(tablename_to_dataframe):\n",
    "    \"\"\"\n",
    "    Write data from provided dataframes to corresponding tables in the database.\n",
    "    \n",
    "    Args:\n",
    "        tablename_to_dataframe (dict): A dictionary mapping table names to dataframes.\n",
    "    \"\"\"\n",
    "    for table_name, dataframe in tablename_to_dataframe.items():\n",
    "        if table_name != \"rents\":\n",
    "            dataframe.to_postgis(table_name, engine, if_exists='replace', index=False)\n",
    "        else:\n",
    "            dataframe.to_sql(table_name, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f042f5-8270-477d-929a-872f7d9a0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename_to_dataframe = {\n",
    "    \"zipcodes\": geodf_zipcode_data,\n",
    "    \"complaints\": geodf_311_data,\n",
    "    \"trees\": geodf_tree_data,\n",
    "    \"rents\": df_zillow_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d052c50-1e43-4356-bcac-4f5abc7e714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(tablename_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4708cb4-d034-43b6-955b-a21d0eab74d4",
   "metadata": {},
   "source": [
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ddbad-3b11-47a2-9245-935f482fa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b21c6-59d9-4bae-8c33-ab4b49ff2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in geodf_tree_data.iterrows():\n",
    "    tree = Tree(...)\n",
    "    session.add(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4bfb9-4fbc-45fe-8a98-a760a22234f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63b553-0c64-4da8-9fc7-41555d89d853",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce8548-4aba-4bf9-992c-dedd0f249db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    \"\"\"\n",
    "    Write a SQL query to a file.\n",
    "    \n",
    "    Parameters:\n",
    "        query (str): The SQL query string to be written to the file.\n",
    "        outfile (str): The path to the file where the query will be saved.\n",
    "    \"\"\"\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)\n",
    "    print(f\"Query written to {outfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7e12b-e251-4f08-8dc5-601db30c2089",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605e6f3-ec42-4a8b-833c-5138c14b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"complaints_per_zipcode.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS num_complaints\n",
    "FROM complaints\n",
    "WHERE date BETWEEN TIMESTAMP '2022-10-01 00:00:00' AND TIMESTAMP '2023-09-30 23:59:59'\n",
    "GROUP BY zipcode;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce044adf-ecdf-4237-9b20-b7cdaaab0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b2c3d-8961-4c7e-8eb1-fc973d0ab9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b60f6",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ce5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR / \"top_10_zipcodes_with_most_trees.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS total_trees\n",
    "FROM trees\n",
    "GROUP BY zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8a878",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = QUERY_DIR / \"average_rent_by_zipcode.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "SELECT trees.zipcode, TO_CHAR(AVG(rents.rent), 'FM9,999,999.00') AS august_rent\n",
    "FROM trees\n",
    "JOIN rents ON trees.zipcode = rents.zipcode\n",
    "WHERE EXTRACT(MONTH FROM rents.date) = 8 AND EXTRACT(YEAR FROM rents.date) = 2023\n",
    "GROUP BY trees.zipcode\n",
    "ORDER BY COUNT(*) DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea916af",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = QUERY_DIR / \"correlation_between_rent_trees_complaints.sql\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "SELECT\n",
    "    rs.zipcode,\n",
    "    TO_CHAR(AVG(rs.avg_rent), 'FM9,999,999.00') as average_rent,\n",
    "    COUNT(DISTINCT t.id) AS tree_count,\n",
    "    COUNT(DISTINCT c.id) AS complaint_count\n",
    "FROM (\n",
    "    SELECT\n",
    "        r.zipcode,\n",
    "        AVG(r.rent) AS avg_rent,\n",
    "        ROW_NUMBER() OVER (ORDER BY AVG(r.rent) ASC) AS low_rank,\n",
    "        ROW_NUMBER() OVER (ORDER BY AVG(r.rent) DESC) AS high_rank\n",
    "    FROM\n",
    "        rents r\n",
    "    WHERE\n",
    "        r.date BETWEEN '2023-01-01' AND '2023-01-31'\n",
    "        AND r.rent IS NOT NULL\n",
    "    GROUP BY\n",
    "        r.zipcode\n",
    ") rs\n",
    "LEFT JOIN\n",
    "    trees t ON rs.zipcode = t.zipcode\n",
    "LEFT JOIN\n",
    "    complaints c ON rs.zipcode = c.zipcode\n",
    "WHERE\n",
    "    rs.low_rank <= 5 OR rs.high_rank <= 5\n",
    "GROUP BY\n",
    "    rs.zipcode, rs.avg_rent\n",
    "ORDER BY\n",
    "    rs.avg_rent, rs.zipcode;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_4))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d3097",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = QUERY_DIR / \"the_most_greenery_areas.sql\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "SELECT zipcodes.zipcode, COUNT(*) AS total_trees\n",
    "FROM zipcodes\n",
    "JOIN trees ON ST_Within(trees.geometry, zipcodes.geometry)\n",
    "GROUP BY zipcodes.zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db59d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_5))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b935f69",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b751e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = QUERY_DIR / \"trees_within_coordinate.sql\"\n",
    "\n",
    "QUERY_6 = '''SELECT\n",
    "    id,\n",
    "    species,\n",
    "    health,\n",
    "    status,\n",
    "    ST_AsText(geometry) AS \"Location\"\n",
    "FROM\n",
    "    trees\n",
    "WHERE\n",
    "    ST_DWithin(\n",
    "        geometry,\n",
    "        ST_SetSRID(ST_MakePoint(-73.96253174434912, 40.80737875669467), 4326),\n",
    "        804.67\n",
    "    );\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_6))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99184f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75223ce5-6ab5-4613-b6af-fa8e33bcc7d5",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcfed-ddbb-4908-a60e-ed7cbc6d5b00",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e2cde-e43b-407b-ab93-ff85a2dba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_complaints_types(dataframe):\n",
    "    \"\"\"\n",
    "    Generate a bar chart to visualize the top 3 complaint types.\n",
    "\n",
    "    This function takes a DataFrame containing complaint data and uses it to produce \n",
    "    a bar chart. The chart displays the frequency of the top 3 types of complaints, \n",
    "    helping to identify the most common issues reported in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe: A pandas DataFrame that contains these two columns:\n",
    "                 'complaint_type' for the type of complaint, and \n",
    "                 'complaint_count' for the number of complaints of that type.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    ax.bar(dataframe['complaint_type'], dataframe['complaint_count'])\n",
    "\n",
    "    ax.set_title(\"Top 3 Complaint Types\")\n",
    "    ax.set_xlabel(\"Complaint Type\")\n",
    "    ax.set_ylabel(\"Number of Complaints\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80755f-d1e1-4e53-8ef8-f5295c59a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    \"\"\"\n",
    "    Retrieve and return data for visualization.\n",
    "\n",
    "    This function executes a SQL query to find the top 3 most common complaint types\n",
    "    from the 'complaints' table between '2022-10-01' and '2023-09-30'. It groups the\n",
    "    complaints by type and date, counts the occurrences, and orders them in descending\n",
    "    order of frequency.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the top 3 complaint types, their respective\n",
    "                      dates, and the count of occurrences on those dates.\n",
    "    \"\"\"\n",
    "    VISUAL_QUERY_1 = \"\"\"\n",
    "    SELECT\n",
    "        complaint_type,\n",
    "        date_trunc('day', date) AS complaint_date,\n",
    "        COUNT(*) AS complaint_count\n",
    "    FROM\n",
    "        complaints\n",
    "    WHERE\n",
    "        date_trunc('day', date) >= '2022-10-01' \n",
    "    AND \n",
    "        date_trunc('day', date) <= '2023-09-30'\n",
    "    GROUP BY\n",
    "        complaint_type, complaint_date\n",
    "    ORDER BY\n",
    "        complaint_count DESC\n",
    "    LIMIT 3;\n",
    "    \"\"\"\n",
    "    return pd.read_sql(VISUAL_QUERY_1, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2632a-b516-4a6e-8b67-97116ab6fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_visual_1 = get_data_for_visual_1()\n",
    "top_3_complaints_types(dataframe_for_visual_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a758dc",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20190a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_complaints(dataframe):\n",
    "    \"\"\"\n",
    "    Generate a bar chart to visualize the most common complaints.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing complaint data.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.bar(dataframe.complaint_type, dataframe.num_complaints)\n",
    "    plt.xlabel('Complaint Type')\n",
    "    plt.ylabel('Number of Complaints')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Most Common Complaints')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_2():\n",
    "    \"\"\"\n",
    "    Retrieve and return data for visualization.\n",
    "    \n",
    "    This function executes a SQL query to get complaint data for the top 10 complaint types\n",
    "    in zip code 10027 within a specific time range.\n",
    "\n",
    "    Returns:\n",
    "        result_df (pd.DataFrame): DataFrame containing the query results.\n",
    "    \"\"\"\n",
    "    VISUAL_QUERY_2 = \"\"\"\n",
    "    SELECT\n",
    "        complaint_type,\n",
    "        COUNT(*) AS num_complaints\n",
    "    FROM\n",
    "        complaints\n",
    "    WHERE\n",
    "        date BETWEEN TIMESTAMP '2018-10-01 00:00:00' AND TIMESTAMP '2023-09-30 23:59:59'\n",
    "        AND zipcode = '10027'\n",
    "    GROUP BY\n",
    "        complaint_type\n",
    "    ORDER BY\n",
    "        num_complaints DESC\n",
    "    LIMIT 10;\n",
    "    \"\"\"\n",
    "\n",
    "    result_df = pd.read_sql_query(VISUAL_QUERY_2, engine)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1660c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_visual_2 = get_data_for_visual_2()\n",
    "most_common_complaints(dataframe_for_visual_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726bc818",
   "metadata": {},
   "source": [
    "### Visualization 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0793b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_with_rents_trees_complaints(dataframe):\n",
    "    \"\"\"\n",
    "    Generate two graphs to visualize the correlations between average rents and number of trees,\n",
    "    and between average rents and number of complaints per zip code.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing rent, tree, and complaint data.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.scatter(dataframe.avg_rent, dataframe.num_trees, s=5, color='green')\n",
    "    plt.ylabel('Number of Trees')\n",
    "    plt.title('Correlation Between Rents and Trees')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.scatter(dataframe.avg_rent, dataframe.num_complaints, s=5, color='orange')\n",
    "    plt.xlabel('Average Rent')\n",
    "    plt.ylabel('Number of Complaints')\n",
    "    plt.title('Correlation Between Rents and Complaints')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_3():\n",
    "    \"\"\"\n",
    "    Retrieve data for visualizing the correlation between rent, number of trees,\n",
    "    and number of complaints by zip code within a specific time range.\n",
    "\n",
    "    Returns:\n",
    "        result_df (pd.DataFrame): DataFrame containing the query results.\n",
    "    \"\"\"\n",
    "    VISUAL_QUERY_3 = \"\"\"\n",
    "    SELECT\n",
    "        rents.zipcode,\n",
    "        AVG(rents.rent) AS avg_rent,\n",
    "        COUNT(DISTINCT trees.id) AS num_trees,\n",
    "        COUNT(DISTINCT complaints.id) AS num_complaints\n",
    "    FROM\n",
    "        rents\n",
    "    LEFT JOIN\n",
    "        trees ON rents.zipcode = trees.zipcode\n",
    "    LEFT JOIN\n",
    "        complaints ON rents.zipcode = complaints.zipcode\n",
    "    WHERE\n",
    "        complaints.date BETWEEN TIMESTAMP '2015-01-01 00:00:00' AND TIMESTAMP '2023-09-30 23:59:59'\n",
    "    GROUP BY\n",
    "        rents.zipcode\n",
    "    \"\"\"\n",
    "    return pd.read_sql(VISUAL_QUERY_3, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6051a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_visual_3 = get_data_for_visual_3()\n",
    "correlation_with_rents_trees_complaints(dataframe_for_visual_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa0950",
   "metadata": {},
   "source": [
    "### Visualization 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rents_and_complaints(dataframe):\n",
    "    \"\"\"\n",
    "    Generate a boxplot to visualize the relationship between rents and number of complaints.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing complaint data.\n",
    "    \"\"\"\n",
    "    data_series = [dataframe.loc[dataframe['bin'] == label, 'num_complaints'] for label in sorted(dataframe['bin'].unique())]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.boxplot(data_series, labels=sorted(dataframe['bin'].unique()))\n",
    "    plt.xlabel('Average Rent in Sep 2023')\n",
    "    plt.ylabel('Number of Complaints')\n",
    "    plt.title('Rent and Complaints')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859426f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_4():\n",
    "    \"\"\"\n",
    "    Retrieve and return data for visualization.\n",
    "    \n",
    "    This function executes a SQL query to get average rent data in September 2023\n",
    "    and complaints data in each zipcode within a specific time range.\n",
    "\n",
    "    Returns:\n",
    "        result_df (pd.DataFrame): DataFrame containing the query results.\n",
    "    \"\"\"\n",
    "    VISUAL_QUERY_4 = \"\"\"\n",
    "    SELECT\n",
    "        complaints.zipcode,\n",
    "        AVG(rents.rent) AS september_rent,\n",
    "        COUNT(*) AS num_complaints\n",
    "    FROM\n",
    "        complaints\n",
    "    JOIN\n",
    "        rents ON complaints.zipcode = rents.zipcode\n",
    "    WHERE\n",
    "        complaints.date BETWEEN TIMESTAMP '2022-10-01 00:00:00' AND TIMESTAMP '2023-09-30 23:59:59'\n",
    "        AND EXTRACT(MONTH FROM rents.date) = 9 AND EXTRACT(YEAR FROM rents.date) = 2023\n",
    "    GROUP BY\n",
    "        complaints.zipcode\n",
    "    ORDER BY\n",
    "        september_rent DESC;\n",
    "    \"\"\"\n",
    "\n",
    "    result_df = pd.read_sql_query(VISUAL_QUERY_4, engine)\n",
    "    bins = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "    result_df['bin'] = pd.cut(result_df['september_rent'], bins, labels=[f'${i}-{j}' for i, j in zip(bins[:-1], bins[1:])])\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_visual_4 = get_data_for_visual_4()\n",
    "rents_and_complaints(dataframe_for_visual_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fbcf1c",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates_of_reported_311_incidents(dataframe):\n",
    "    \"\"\"\n",
    "    Plots a geospatial map of 311 incidents.\n",
    "\n",
    "    This function takes a GeoDataFrame containing the coordinates of 311 incidents and plots them \n",
    "    on a map. Each point on the map represents a reported incident. The plot is useful for visualizing \n",
    "    the geographical distribution of incidents within the specified area and time frame.\n",
    "\n",
    "    Parameters:\n",
    "        gpd.GeoDataFrame: A GeoDataFrame containing the coordinates of the reported 311 incidents.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = plt.axes()\n",
    "    dataframe.plot(ax=ax, markersize=5)\n",
    "    ax.set_title(\"Reported 311 Incidents from Jan 1, 2023 to Sep 30, 2023\")\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac596601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_5():\n",
    "    \"\"\"\n",
    "    Retrieves the coordinates of 311 incidents reported within a specific radius and time frame.\n",
    "\n",
    "    This function queries the database for 311 incidents that occurred between January 1st, 2023,\n",
    "    and September 30th, 2023, and within a 1-kilometer radius of a given coordinate point. \n",
    "    It returns a GeoDataFrame containing the latitude and longitude of each incident.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: A GeoDataFrame containing the coordinates of the reported incidents.\n",
    "    \"\"\"\n",
    "    VISUAL_QUERY_5 = \"\"\"\n",
    "    SELECT \n",
    "        ST_Y(geometry) AS latitude, \n",
    "        ST_X(geometry) AS longitude\n",
    "    FROM \n",
    "        complaints\n",
    "    WHERE \n",
    "        ST_DWithin(\n",
    "            geometry, \n",
    "            ST_SetSRID(ST_MakePoint(-73.96253174434912, 40.80737875669467), 4326), \n",
    "            1000\n",
    "        )\n",
    "      AND \n",
    "        date_trunc('day', date) >= '2023-01-01' \n",
    "      AND \n",
    "        date_trunc('day', date) <= '2023-09-30'\n",
    "    \"\"\"\n",
    "    return gpd.GeoDataFrame(\n",
    "        pd.read_sql(VISUAL_QUERY_5, engine),\n",
    "        geometry=gpd.points_from_xy(pd.read_sql(VISUAL_QUERY_5, engine)['longitude'], pd.read_sql(VISUAL_QUERY_5, engine)['latitude'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_visual_5 = get_data_for_visual_5()\n",
    "coordinates_of_reported_311_incidents(dataframe_for_visual_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6c707",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trees_and_tree_requests(dataframe_1, dataframe_2):\n",
    "    \"\"\"\n",
    "    Generate a bar chart to visualize the most common complaints.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing complaint data.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(dataframe_1.longitude, dataframe_1.latitude, s=5, label='Trees')\n",
    "    plt.scatter(dataframe_2.longitude, dataframe_2.latitude, s=5, label='Complaints')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('Trees and New Tree Request Complaints')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a51e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_6():\n",
    "    \"\"\"\n",
    "    Retrieve and return data for visualization.\n",
    "\n",
    "    This function executes two SQL queries to get the coordinates of trees,\n",
    "    and the coordinates of New Tree Request within a specific time range.\n",
    "\n",
    "    Returns:\n",
    "        result_1 (gpd.GeoDataFrame): GeoDataFrame containing trees data.\n",
    "        result_2 (gpd.GeoDataFrame): GeoDataFrame containing complaints data.\n",
    "    \"\"\"\n",
    "    VISUAL_QUERY_6_1 = \"\"\"\n",
    "    SELECT\n",
    "        ST_X(geometry) AS longitude,\n",
    "        ST_Y(geometry) AS latitude\n",
    "    FROM\n",
    "        trees\n",
    "    \"\"\"\n",
    "\n",
    "    VISUAL_QUERY_6_2 = \"\"\"\n",
    "    SELECT\n",
    "        ST_X(geometry) AS longitude,\n",
    "        ST_Y(geometry) AS latitude\n",
    "    FROM\n",
    "        complaints\n",
    "    WHERE\n",
    "        complaint_type = 'New Tree Request' AND\n",
    "        complaints.date BETWEEN TIMESTAMP '2018-10-01 00:00:00' AND TIMESTAMP '2023-09-30 23:59:59'\n",
    "    \"\"\"\n",
    "\n",
    "    result_df_1 = pd.read_sql_query(VISUAL_QUERY_6_1, engine)\n",
    "    result_df_2 = pd.read_sql_query(VISUAL_QUERY_6_2, engine)\n",
    "\n",
    "    result_1 = gpd.GeoDataFrame(\n",
    "        result_df_1,\n",
    "        geometry=gpd.points_from_xy(result_df_1.longitude, result_df_1.latitude)\n",
    "    )\n",
    "    result_2 = gpd.GeoDataFrame(\n",
    "        result_df_2,\n",
    "        geometry=gpd.points_from_xy(result_df_2.longitude, result_df_2.latitude)\n",
    "    )\n",
    "\n",
    "    return result_1, result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d88d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_for_visual_6_1, dataframe_for_visual_6_2 = get_data_for_visual_6()\n",
    "trees_and_tree_requests(dataframe_for_visual_6_1, dataframe_for_visual_6_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
